<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0>

  <!-- Google Font(s) -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&family=Roboto:wght@300;400&display=swap" rel="stylesheet">

  <!-- CSS stylesheet -->
  <link rel="stylesheet" type="text/css" href="style.css" />
</head>

<body>
  <div id="container">
    <div id="proposal">
      <h1>Proposal</h1>
      <h2>If Sound Could Draw</h2>
      <h3>Description of the Project</h3>
      <h4>Response to Question 1</h4>
      <p>My goal is to create a data visualization that illustrates a pattern by capturing the invisible properties of
        sound. Despite my appreciation for audio, it often feels like a confusing and abstract concept. For tactile
        or visual learnings like myself, it may seem like an intimidating domain to grasp, explore, and experiment
        with. By exploiting auditory information to create designs, my aim is to create an amusing interface that
        attenuates some of the ambiguity that individuals like myself associate with sound. They can use their
        voice, instruments, natural noises, or any other audio as input to output a visual representation on their
        device’s screen. The pattern is constructed based on changes in the detected characteristics (i.e. volume
        and frequency) of the registered sound. As variations in the audio occur (i.e. increased pitch), the user
        can observe changes in the design (i.e. stroke weight becomes more narrow) to give them information
        about which sound properties are affected.
        Once they have completed their design, users will be encouraged to post it to the website, resulting in a
        small online community where people can share their experience with others. They will be able to add
        their name, location, and a short description of the sounds they used. They may also remain anonymous
        when posting their work. Additionally, they have the option of downloading their work, or erasing it
        completely. The purpose of this feature is to promote their participation in building this online network
        without forcing them to.</p><br>

      <h4>Response to Question 2</h4>
      <p>I wish to encourage users to be experimental with the interface. They get to control the input so they can
        try different audio sources like their own voice, sounds from their environment, animals, music, etc. They
        can also overlap sounds and alter them in certain ways to see how the pattern is affected. As they experiment with the audio, the visual depiction will respond so they can better understand the results of their
        actions. This project will, for some, offer a deeper understanding of certain audible properties that make
        up sounds. This will also give them the opportunity to reflect on the sounds that make up their environment. They may, for example, capture the sounds of wind and rain through the microphone to experience
        them through a different sense. Alternatively, they may rub two objects or materials together to see what
        kind of information results from this interaction. Overall, users can discover themselves when using their
        own voice or musical production, discover their environment by capturing the surrounding sounds, or
        learn more about their actions by initiating interactions between objects.</p><br>

      <h4>Response to Question 3</h4>
      <p>My project will help users gain a new awareness of the sounds they produce and are surrounded with.
        For users who find the concept of sound to be confusing or abstract-seeming, the visual depiction will
        help them better understand the information that can be gathered from audio. It may also challenge
        what they think they know about sound. Although they will not be able to directly edit the pattern, they
        are able to modify it by altering or changing the sound itself. Ultimately, they are in control of the design
        since it is being illustrated based on the input they give. However, they must learn how to manipulate the
        properties of the sound if they wish to have more control over the design. This may simultaneously feel
        empowering and disorderly to the user.
        By giving them the ability to post their creations and view those made by others in a collective virtual
        space, they are encouraged to share their experience with others. The display of works on the website
        therefore becomes a space for collaboration. As they view the artworks and captions posted by other
        users, they gain information about each other and the type of sound used to create each design. Significantly, users are able to participate while maintaining anonymity. This gives them the opportunity to
        engage in the project without the obligation of sharing personal details.</p><br>

        <h3>Storyboard</h3>
        <img src="images/storyboard.png" width="700" height="906" alt="storyboard">


      <h3>Similar Projects</h3>
      <h4>Seeing Music by Jay Alan Zimmerman and Google</h4>
      <a href="https://creatability.withgoogle.com/seeing-music/" target="_blank">https://creatability.withgoogle.com/seeing-music/</a>
      <p>Seeing Music is an inspiring Google experiment by Jay Alan Zimmerman that gives the user the ability
        to experience music visually. The user turns on their microphone or imports a sound file then selects
        between two modes: Basic mode and Piano mode. Basic mode is used for monophonic music and piano
        mode is for polyphonic music. Piano mode is built using a machine learning model designed by a team
        at Google. An on-screen keyboard is available for the user to visualize live piano performances. They are
        also presented with some settings to determine the type of visual representation they would like to see.
        These are based on sound textures and paths of melodies. There are nine settings to choose from such
        as Hilbert Scope, Spectrograph, and Waveform. When the user changes settings, the visual is erased and
        restarts in the new style. There are also a few sample sounds available so users can see examples without
        activating their microphone or importing any files. There are additional settings to toggle between colour
        modes (grayscale or RGB) and to activate grids and nodes. By letting individuals activate their microphones to input live information all while presenting them with modes and settings to customize their
        visual experience, there is a high level of interaction between the project and its users. According to the
        project description, it was built using Tone.js, WebRTC, Tensorflow.js, and Magenta.js.</p><br>

      <h4>Spectrogram by Jeramy Morrill and Boris Smus</h4>
      <a href="https://musiclab.chromeexperiments.com/Spectrogram/" target="_blank">https://musiclab.chromeexperiments.com/Spectrogram/</a>
      <p>Spectrogram is a digital tool published in the Chrome Music Lab experiments by Jeramy Morrill and Boris
        Smus. The website lets users compare the spectrograms of different sounds, or activate their device’s
        microphone to visualize their own input. Besides using their own audio, there are several other embedded options to choose from including flute, harp, whistling, trombone, drums, birds, modem, and wine
        glass noises. There is also a feature to click and drag the cursor across the screen to produce sounds.
        The result is an RGB spectrogram with a three-dimensional look. Morrill and Smus’ tool seems to be an
        amusing experiment that invites users to explore and play with the sound options to experience different
        visual outcomes. It specifically measures variations in signal frequencies over time, so the user only gains
        an understanding of one sound property. Overall, it is straight-forward to use and does not include many
        features for users to customize their experience or gain a more in-depth understanding of the different
        components that make up sounds. It is, however, a useful tool to learn about audio frequency and the
        tendencies of certain noises and instruments to have more regular or varying frequencies.</p><br>

      <h4>Off the Staff by Nicholas Rougeux</h4>
      <a href="https://www.c82.net/offthestaff/" target="_blank">https://www.c82.net/offthestaff/</a>
      <p>Off the Staff is an experiment to visualize notes from music scores. The work was created by Nicholas
        Rougeux, who is an inspiring web designer and data artist. He creates arrangements of dots using the
        notes in the score, and they are distanced from the center of the design according to the pitch. The dots
        are sized based on the duration of each note and progressively appear in a circular pattern relative to the
        time at which they occur. They are colourized to represent different instruments.
        Rougeux uses classical songs such as The Four Seasons by Antonio Vivaldi and Allegro con brio by Ludwig
        van Beethoven. By the end of each tune, posters are created with the resulting designs, which are available for purchase through his website. Rougeux also publishes videos so people can discover how each
        poster was created. Since the design varies based on changes in the score notes, users get to experience
        the music both audibly and visually. In other words, they gain a new understanding of the notes they
        are hearing as they encounter them through two senses instead of one. Additionally, there are links to
        the sheet music for users to consult. The process videos and resulting poster designs are fascinating and
        unlike any other work I have come across. On his portfolio website, Rougeux explains the method and
        technologies behind his work so users gain an insight into how his project came to life.</p><br>

      <h3>How My Project Will Be Different</h3>
      <p>The three projects previously discussed are similar to my project concept as they are all data visualizations of sound. I chose those examples specifically because they all approach a similar objective in distinguished ways and using
        different
        technologies. To my understanding, Seeing Music and Spectrogram are
        primarily tools for experimentation and exploration. There is no actual product from this experience. Off
        the Staff, on the other hand, is a collection of designs derived from experiments conducted by Rougeux.
        In this case, there are products but users are not given the opportunity to participate in their creation.
        My project will be different by giving individuals the ability to explore and experiment with the tool, and
        to create their own products as a result of this interaction. Unlike the three examples, I want to give
        users a space to share their designs and browse those made by others. This collective virtual space will
        ultimately encourage the sharing of information while simultaneously promoting collaboration.</p><br>

      <a href="projects/proposal.pdf" target="_blank">Link to PDF Version</a><br><br><br>

    </div>
  </div> <!-- closing container -->
</body>

</html>
